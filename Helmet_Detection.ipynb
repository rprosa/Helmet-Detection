{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_0mZYE83K7Al",
        "outputId": "d191e675-d9b4-425e-9963-a70cfe685da6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping wandb as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m^C\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y wandb\n",
        "!pip uninstall -y torch torchvision torchaudio ultralytics -q\n",
        "!pip install -q torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cpu\n",
        "!pip install -q ultralytics==8.1.13 tqdm kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TV2w65vTK3ZN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['WANDB_DISABLED'] = 'true'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79wLe5IqK8zk",
        "outputId": "0ec0c8e7-b389-427c-970c-4846f7c60c9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Novo data.yaml criado com as 4 classes.\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "Path('/content/helmetbehincode').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "data_yaml_text = \"\"\"\n",
        "path: /content/helmetbehincode\n",
        "train: train/images\n",
        "val: valid/images\n",
        "\n",
        "names:\n",
        "  0: rider\n",
        "  1: helmet\n",
        "  2: no_helmet\n",
        "\"\"\"\n",
        "\n",
        "Path('/content/helmetbehincode/data.yaml').write_text(data_yaml_text)\n",
        "print(\"âœ… Novo data.yaml criado com as 4 classes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duCWnBucK86i",
        "outputId": "4eb2192b-a659-4aac-c5c7-187d92b5f507"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/abuzarkhaaan/helmetbehncode\n",
            "License(s): Community Data License Agreement - Permissive - Version 1.0\n",
            "Downloading helmetbehncode.zip to /content\n",
            " 54% 69.0M/128M [00:00<00:00, 719MB/s]\n",
            "100% 128M/128M [00:00<00:00, 486MB/s] \n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/root/.kaggle/kaggle.json'):\n",
        "    files.upload()\n",
        "    !mkdir -p ~/.kaggle && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d abuzarkhaaan/helmetbehncode -p /content --unzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6zK_J0uK9BE",
        "outputId": "14d127ec-7405-4944-f1fb-a35dd446036c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Movido: train/ â†’ helmetbehincode/train/\n",
            "âœ… Movido: valid/ â†’ helmetbehincode/valid/\n",
            "âœ… Movido: test/ â†’ helmetbehincode/test/\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "base_dir = '/content'\n",
        "dest_dir = os.path.join(base_dir, 'helmetbehincode')\n",
        "os.makedirs(dest_dir, exist_ok=True)\n",
        "\n",
        "for folder in ['train', 'valid', 'test']:\n",
        "    src = os.path.join(base_dir, folder)\n",
        "    dst = os.path.join(dest_dir, folder)\n",
        "    if os.path.exists(src):\n",
        "        shutil.move(src, dst)\n",
        "        print(f\"âœ… Movido: {folder}/ â†’ helmetbehincode/{folder}/\")\n",
        "    else:\n",
        "        print(f\"âš ï¸ Pasta nÃ£o encontrada: {src}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKOM2L-oK9Dc",
        "outputId": "ea662018-0e4a-40bb-83cd-39ff4b1540d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New https://pypi.org/project/ultralytics/8.3.161 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.1.13 ðŸš€ Python-3.11.13 torch-2.3.0+cpu CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/helmetbehincode/data.yaml, epochs=5, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=helmet-detection, name=helmet_detection_extended45, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=helmet-detection/helmet_detection_extended45\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3011433 parameters, 3011417 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir helmet-detection/helmet_detection_extended45', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/helmetbehincode/train/labels.cache... 1629 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1629/1629 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.11/dist-packages/ultralytics/data/augment.py:846: UserWarning: Argument(s) 'quality_lower' are not valid for transform ImageCompression\n",
            "  A.ImageCompression(quality_lower=75, p=0.0),\n",
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
            "  self._set_keys()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/helmetbehincode/valid/labels.cache... 155 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 155/155 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to helmet-detection/helmet_detection_extended45/labels.jpg... \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mhelmet-detection/helmet_detection_extended45\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        1/5         0G      1.537      2.422      1.872         74        640:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/102 [10:59<10:34, 12.70s/it]"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import random\n",
        "import glob\n",
        "import os\n",
        "from IPython.display import Image, display\n",
        "\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "results = model.train(\n",
        "    data='/content/helmetbehincode/data.yaml',\n",
        "    epochs=5,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    name='helmet_detection_extended4',\n",
        "    project='helmet-detection'\n",
        ")\n",
        "\n",
        "modelo_treinado = YOLO('/content/helmet-detection/helmet_detection_extended4/weights/best.pt')\n",
        "\n",
        "image_paths = glob.glob('/content/helmetbehincode/valid/images/*.jpg')\n",
        "\n",
        "for i in range(3):\n",
        "    img_path = random.choice(image_paths)\n",
        "\n",
        "    pred = modelo_treinado.predict(source=img_path, conf=0.25, save=True, verbose=False)\n",
        "    pred_path = os.path.join(pred[0].save_dir, os.path.basename(img_path))\n",
        "\n",
        "    display(Image(filename=pred_path))\n",
        "    print(f\"ðŸ–¼ï¸ Exibind imagens com prediÃ§Ã£os: {os.path.basename(img_path)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eq-DdqnaK9Hs"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m metrics = \u001b[43mmodel\u001b[49m.val(data=\u001b[33m'\u001b[39m\u001b[33m/content/helmetbehincode/data.yaml\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmAP50-95: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics.box.map\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m metrics.confusion_matrix.plot(save_dir=\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "metrics = model.val(data='/content/helmetbehincode/data.yaml')\n",
        "print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
        "metrics.confusion_matrix.plot(save_dir='.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOwS0v_pK9Jj"
      },
      "outputs": [],
      "source": [
        "!find /content -name \"best.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W259BFw0MP5M"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/helmet-detection/helmet_detection_extended2/weights/best.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9ChKDZL3vI2"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import glob\n",
        "import os\n",
        "from IPython.display import Image, display\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('/content/helmet-detection/helmet_detection_extended2/weights/best.pt')\n",
        "\n",
        "image_paths = glob.glob('/content/helmetbehincode/valid/images/*.jpg')\n",
        "\n",
        "for i in range(3):\n",
        "    random_image = random.choice(image_paths)\n",
        "\n",
        "    results = model.predict(\n",
        "        source=random_image,\n",
        "        conf=0.25,\n",
        "        save=True\n",
        "    )\n",
        "\n",
        "    pred_path = os.path.join(results[0].save_dir, os.path.basename(random_image))\n",
        "\n",
        "    display(Image(filename=pred_path))\n",
        "    print(f\"âœ… ({i+1}/3) Imagem: {os.path.basename(random_image)}\") #caso, professor, deseja aumentar o nÂº de imagens, altere o \"/3\" para o nÂº q desejar!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJz8v1D3MTxd"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import Image, display\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()\n",
        "fname = next(iter(uploaded))\n",
        "\n",
        "model = YOLO('/content/helmet-detection/helmet_detection_extended2/weights/best.pt')\n",
        "\n",
        "results = model.predict(\n",
        "    source=fname,\n",
        "    conf=0.25,\n",
        "    save=True\n",
        ")\n",
        "\n",
        "save_dir = results[0].save_dir\n",
        "pred_path = os.path.join(save_dir, fname)\n",
        "\n",
        "display(Image(pred_path))\n",
        "print(\"âœ… DetecÃ§Ã£o finalizada e imagem exibida!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "axy1JLcPrmot"
      },
      "outputs": [],
      "source": [
        "# 1. Instala a biblioteca necessÃ¡ria para conversÃ£o\n",
        "!pip install -q moviepy\n",
        "\n",
        "# 2. Converte o GIF para MP4\n",
        "import moviepy.editor as mp\n",
        "\n",
        "gif_clip = mp.VideoFileClip(\"/content/teste.gif\")  # Altere se o nome for diferente\n",
        "gif_clip.write_videofile(\"/content/teste.mp4\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tqH_U6159KvY"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO('/content/helmet-detection/helmet_detection_extended2/weights/best.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Vo1Y6m2R_ETN"
      },
      "outputs": [],
      "source": [
        "results = model.predict(\n",
        "    source=\"/content/teste.mp4\",\n",
        "    conf=0.1,\n",
        "    save=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xX8NoYnQBDtL"
      },
      "outputs": [],
      "source": [
        "!ffmpeg -i /content/runs/detect/predict39/teste.avi /content/runs/detect/predict39/teste.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEvyTm2e_V58"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Video\n",
        "Video(\"/content/runs/detect/predict39/teste.mp4\", embed=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
